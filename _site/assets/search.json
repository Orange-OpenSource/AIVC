

[
  
  
    
    
  
  
  
  {
    "title": "AIVC",
    "excerpt": "\n",
    "content": "AI-based Video Codec is an end-to-end neural video coder, offering many practical features and great flexibility:\n\n\n  \n    \n      Features\n      What’s inside?\n    \n  \n  \n    \n      Coding configurations\n      Random Access, Low-delay P &amp; All Intra\n    \n    \n      Tunable Intra Period\n      Up to 64\n    \n    \n      Tunable GOP size\n      Up to 64\n    \n    \n      7 Different rates target\n      1 MBit/s to 20 MBit/s (for 1080p videos)\n    \n    \n      Competitive performances\n      On par with HM (HEVC Test Model)\n    \n    \n      Convenient input format\n      8-bit YUV 4:2:0 videos\n    \n  \n\n\n\n\nGet the models  github\n\n Read the paper ☕️\n See some slides\n\n",
    "url": "/"
  },
  
  {
    "title": "Categories",
    "excerpt": "Category index\n",
    "content": "\n",
    "url": "/rd_results/"
  },
  
  {
    "title": "Visual Examples",
    "excerpt": "Visual examples of AIVC behavior\n",
    "content": "\n\n\n\n\n\nWorks on firefox and Safari!\n\nExamples are presented on the video sequence Sports_1080P-6710 from the\nCLIC 2021 dataset.\n\n{% include figure.html image=”../assets/diagram/Global_diagram.png” alt=”Image with just alt text” %}\n\nVideos from the paper\n\nThe videos presented here are from the Fig. 2 in the paper AIVC: Artificial\nIntelligence for Video Coding, Ladune et al.\n\n\n  \n    \n      \n        Original video $\\mathbf{x}_t$ \n      \n      \n        \n          \n        \n      \n    \n    \n      \n        Optical flow $\\mathbf{v}_p$ \n      \n      \n        \n          \n        \n      \n    \n    \n      \n        Optical flow $\\mathbf{v}_f$ \n      \n      \n        \n          \n        \n      \n    \n    \n      \n        Coding mode \n        selection $\\boldsymbol{\\alpha}$\n      \n      \n        \n          \n        \n      \n    \n    \n      \n        Skip mode contribution\n        $(1 - \\boldsymbol{\\alpha}) \\odot \\tilde{\\mathbf{x}}_t$ \n      \n      \n        \n          \n        \n      \n    \n    \n      \n        Decoded video $\\hat{\\mathbf{x}}_t$ \n      \n      \n        \n          \n        \n      \n    \n  \n\n\nWe also provide supplementary examples which displays some other quantities at\nstake during the coding of a video sequence.\n\n\n  \n    \n      \n        Bi-directional prediction \n        weighting $\\boldsymbol{\\beta}$\n      \n      \n        \n          \n        \n      \n    \n    \n      \n        Temporal prediction\n        $\\tilde{x}_t$ \n      \n      \n        \n          \n        \n      \n    \n  \n\n\n\nConditional coding behavior\n\nConditional coding plays a key role in AIVC compression performance. In order to\nbetter understand its behavior, we present some insightful videos based on the\nseparate synthesis of the analysis and conditioning MNet latent variables. We’ll\nhave a look at one optical flow $\\mathbf{v}_p$ when it is synthesized from:\n\n\n  The analysis latent variable only i.e. no decoder-side info used\n  The conditioning latent variable only i.e. not a single bit conveyed\n  Both latent variables\n\n\n\n  \n    \n      \n        Optical flow $\\mathbf{v}_p$\n        Only from conditioning \n        latent variable\n        Decoder-side only!\n      \n      \n        \n          \n        \n      \n    \n    \n      \n        Optical flow $\\mathbf{v}_p$ \n        Only from analysis\n        latent variable \n      \n      \n        \n          \n        \n      \n    \n    \n      \n        Optical flow $\\mathbf{v}_p$ \n        From all latent variables \n      \n      \n        \n          \n        \n      \n    \n  \n\n\nRecall that the conditioning is a decoder-side only transform, so the first\nvideo represents the motion information infered at the decoder without a\nsingle bit received. Most of the small motions in the background are inferred at\nthe decoder thanks to the conditioning transform. Yet, the motion of the girl in\nthe foreground is too complex to be anticipated at the decoder. Thus, the\nanalysis transform transmits motion information solely for the girl.\n",
    "url": "/visual_examples/"
  }
  
]

